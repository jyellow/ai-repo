{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多输入通道和多输出通道\n",
    "\n",
    "前面两节里我们用到的输入和输出都是二维数组，但真实数据的维度经常更高。例如，彩色图像在高和宽2个维度外还有RGB（红、绿、蓝）3个颜色通道。假设彩色图像的高和宽分别是$h$和$w$（像素），那么它可以表示为一个$3\\times h\\times w$的多维数组。我们将大小为3的这一维称为通道（channel）维。本节我们将介绍含多个输入通道或多个输出通道的卷积核。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "这段代码实现了一个单通道的二维互相关（卷积）运算。让我详细解释其功能和实现：\n",
    "\n",
    "1. **函数定义和参数处理**：\n",
    "```python\n",
    "def corr2d(X, K):\n",
    "    h, w = K.shape\n",
    "    if len(X.shape) <= 1:\n",
    "        X = tf.reshape(X, (X.shape[0],1))\n",
    "```\n",
    "\n",
    "- 接收输入X和卷积核K\n",
    "- 获取卷积核的高度和宽度\n",
    "- 处理一维输入的特殊情况，将其转为二维\n",
    "\n",
    "2. **输出初始化**：\n",
    "```python\n",
    "Y = tf.Variable(tf.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1)))\n",
    "```\n",
    "\n",
    "- 计算输出的尺寸：\n",
    "  - 高度 = 输入高度 - 卷积核高度 + 1\n",
    "  - 宽度 = 输入宽度 - 卷积核宽度 + 1\n",
    "- 创建全零变量作为输出\n",
    "\n",
    "3. **卷积计算过程**：\n",
    "```python\n",
    "for i in range(Y.shape[0]):\n",
    "    for j in range(Y.shape[1]):\n",
    "        prod = X[i:i+h, j:j+w] * K\n",
    "        sum_result = tf.reduce_sum(prod)\n",
    "        casted_result = tf.cast(sum_result, dtype=tf.float32)\n",
    "        Y[i,j].assign(casted_result)\n",
    "```\n",
    "\n",
    "具体步骤：\n",
    "- 双重循环遍历输出位置\n",
    "- 对每个位置：\n",
    "  1. 提取输入的对应窗口\n",
    "  2. 与卷积核进行元素乘法\n",
    "  3. 计算乘积的总和\n",
    "  4. 转换为float32类型\n",
    "  5. 赋值给输出张量\n",
    "\n",
    "特点和说明：\n",
    "1. **灵活性**：\n",
    "   - 可处理一维和二维输入\n",
    "   - 自动调整输出大小\n",
    "\n",
    "2. **实现细节**：\n",
    "   - 使用显式循环计算\n",
    "   - 确保数据类型一致性\n",
    "   - 使用assign进行赋值\n",
    "\n",
    "3. **局限性**：\n",
    "   - 仅支持单通道输入\n",
    "   - 计算效率较低\n",
    "   - 没有实现填充和步幅\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):\n",
    "    \"\"\"单通道二维卷积计算\"\"\"\n",
    "    # 获取卷积核的高度和宽度\n",
    "    h, w = K.shape\n",
    "    # 如果输入X是一维的，将其重塑为二维\n",
    "    if len(X.shape) <= 1:\n",
    "        X = tf.reshape(X, (X.shape[0],1))\n",
    "    \n",
    "    # 创建输出变量Y，大小为 (X的高度-卷积核高度+1) x (X的宽度-卷积核宽度+1)\n",
    "    # 初始化二维卷积操作结果形状\n",
    "    Y = tf.Variable(tf.zeros((X.shape[0] - h + 1, X.shape[1] - w +1)))\n",
    "    \n",
    "    # 执行二维互相关运算\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            # 对应位置的元素相乘并求和，然后转换为float32类型\n",
    "            # 计算X和K的对应元素相乘\n",
    "            prod = X[i:i+h, j:j+w] * K\n",
    "            # 对乘积进行求和\n",
    "            sum_result = tf.reduce_sum(prod)\n",
    "            # 将结果转换为float32类型\n",
    "            casted_result = tf.cast(sum_result, dtype=tf.float32)\n",
    "            # 将结果赋值给Y[i,j]\n",
    "            Y[i,j].assign(casted_result)\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3.1 muti-channels in\n",
    "\n",
    "当输入数据含多个通道时，我们需要构造一个输入通道数与输入数据的通道数相同的卷积核，从而能够与含多通道的输入数据做互相关运算。假设输入数据的通道数为$c_i$，那么卷积核的输入通道数同样为$c_i$。设卷积核窗口形状为$k_h\\times k_w$。当$c_i=1$时，我们知道卷积核只包含一个形状为$k_h\\times k_w$的二维数组。当$c_i > 1$时，我们将会为每个输入通道各分配一个形状为$k_h\\times k_w$的核数组。把这$c_i$个数组在输入通道维上连结，即得到一个形状为$c_i\\times k_h\\times k_w$的卷积核。由于输入和卷积核各有$c_i$个通道，我们可以在各个通道上对输入的二维数组和卷积核的二维核数组做互相关运算，再将这$c_i$个互相关运算的二维输出按通道相加，得到一个二维数组。这就是含多个通道的输入数据与多输入通道的卷积核做二维互相关运算的输出。\n",
    "\n",
    "图5.4展示了含2个输入通道的二维互相关计算的例子。在每个通道上，二维输入数组与二维核数组做互相关运算，再按通道相加即得到输出。图5.4中阴影部分为第一个输出元素及其计算所使用的输入和核数组元素：$(1\\times1+2\\times2+4\\times3+5\\times4)+(0\\times0+1\\times1+3\\times2+4\\times3)=56$。\n",
    "\n",
    "![含2个输入通道的互相关计算](../img/conv-multi-in.svg)\n",
    "\n",
    "\n",
    "接下来我们实现含多个输入通道的互相关运算。我们只需要对每个通道做互相关运算，然后进行累加。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "这段代码实现了多通道输入的二维互相关（卷积）运算。让我详细解释其实现逻辑：\n",
    "\n",
    "1. **函数定义**：\n",
    "```python\n",
    "def corr2d_multi_in(X, K):\n",
    "    channel_results = []\n",
    "    for i in range(X.shape[0]):\n",
    "        channel_result = corr2d(X[i], K[i])\n",
    "        channel_results.append(channel_result)\n",
    "    return tf.reduce_sum(channel_results, axis=0)\n",
    "```\n",
    "\n",
    "\n",
    "功能说明：\n",
    "- 接收多通道输入X和对应的多通道卷积核K\n",
    "- 对每个通道分别进行卷积\n",
    "- 将所有通道的结果求和\n",
    "\n",
    "2. **输入数据结构**：\n",
    "```python\n",
    "X = tf.constant([\n",
    "    [[0, 1, 2], [3, 4, 5], [6, 7, 8]],  # 第一个通道\n",
    "    [[1, 2, 3], [4, 5, 6], [7, 8, 9]]   # 第二个通道\n",
    "])\n",
    "```\n",
    "\n",
    "\n",
    "- 形状为(2, 3, 3)\n",
    "- 2个通道\n",
    "- 每个通道是3×3矩阵\n",
    "\n",
    "3. **卷积核结构**：\n",
    "```python\n",
    "K = tf.constant([\n",
    "    [[0, 1], [2, 3]],  # 第一个通道的卷积核\n",
    "    [[1, 2], [3, 4]]   # 第二个通道的卷积核\n",
    "])\n",
    "```\n",
    "\n",
    "\n",
    "- 形状为(2, 2, 2)\n",
    "- 2个通道\n",
    "- 每个通道是2×2卷积核\n",
    "\n",
    "4. **处理流程**：\n",
    "- 对每个通道：\n",
    "  1. 提取当前通道的输入和对应的卷积核\n",
    "  2. 使用corr2d函数计算单通道卷积\n",
    "  3. 将结果存入列表\n",
    "- 最后对所有通道的结果求和\n",
    "\n",
    "特点说明：\n",
    "1. **多通道处理**：\n",
    "   - 支持任意数量的输入通道\n",
    "   - 每个通道有独立的卷积核\n",
    "\n",
    "2. **结果合并**：\n",
    "   - 通过求和合并多通道结果\n",
    "   - 输出是单通道特征图\n",
    "\n",
    "3. **实际应用**：\n",
    "   - 适用于彩色图像处理（如RGB三通道）\n",
    "   - 可处理多特征输入\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X, K):\n",
    "    # 创建一个列表来存储每个通道的互相关结果\n",
    "    channel_results = []\n",
    "    \n",
    "    # 对每个通道进行互相关运算\n",
    "    for i in range(X.shape[0]):\n",
    "        channel_result = corr2d(X[i], K[i])\n",
    "        channel_results.append(channel_result)\n",
    "    \n",
    "    # 在通道维度上对结果进行求和\n",
    "    return tf.reduce_sum(channel_results, axis=0)\n",
    "\n",
    "X = tf.constant([\n",
    "    [[0, 1, 2], [3, 4, 5], [6, 7, 8]],  # 第一个通道\n",
    "    [[1, 2, 3], [4, 5, 6], [7, 8, 9]]   # 第二个通道\n",
    "])  # X 的形状为 (2, 3, 3)，表示 2 个通道，每个通道是 3x3 的矩阵\n",
    "\n",
    "K = tf.constant([\n",
    "    [[0, 1], [2, 3]],  # 第一个通道的卷积核\n",
    "    [[1, 2], [3, 4]]   # 第二个通道的卷积核\n",
    "])  # K 的形状为 (2, 2, 2)，表示 2 个通道，每个通道是 2x2 的卷积核\n",
    "\n",
    "result = corr2d_multi_in(X, K)\n",
    "# print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3.2 multi-channels out\n",
    "\n",
    "当输入通道有多个时，因为我们对各个通道的结果做了累加，所以不论输入通道数是多少，输出通道数总是为1。设卷积核输入通道数和输出通道数分别为$c_i$和$c_o$，高和宽分别为$k_h$和$k_w$。如果希望得到含多个通道的输出，我们可以为每个输出通道分别创建形状为$c_i\\times k_h\\times k_w$的核数组。将它们在输出通道维上连结，卷积核的形状即$c_o\\times c_i\\times k_h\\times k_w$。在做互相关运算时，每个输出通道上的结果由卷积核在该输出通道上的核数组与整个输入数组计算而来。\n",
    "\n",
    "下面我们实现一个互相关运算函数来计算多个通道的输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "这段代码实现了多输入通道和多输出通道的二维互相关（卷积）运算。让我详细解释：\n",
    "\n",
    "1. **函数定义**：\n",
    "```python\n",
    "def corr2d_multi_in_out(X, K):\n",
    "    results = []\n",
    "    for k in K:\n",
    "        result = corr2d_multi_in(X, k)\n",
    "        results.append(result)\n",
    "    return tf.stack(results, axis=0)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "功能说明：\n",
    "- 输入X：包含多个输入通道的数据\n",
    "- 输入K：包含多个输出通道的卷积核组\n",
    "- 返回：多输出通道的卷积结果\n",
    "\n",
    "2. **处理流程**：\n",
    "- 对每个输出通道的卷积核：\n",
    "  1. 使用corr2d_multi_in进行多输入通道卷积\n",
    "  2. 将结果保存到列表中\n",
    "- 最后将所有结果堆叠成多通道输出\n",
    "\n",
    "3. **数据维度变化**：\n",
    "```python\n",
    "# 假设：\n",
    "# X shape: (in_channels, height, width)\n",
    "# K shape: (out_channels, in_channels, kernel_height, kernel_width)\n",
    "# 输出 shape: (out_channels, output_height, output_width)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "4. **关键步骤**：\n",
    "- 循环处理每个输出通道\n",
    "- 使用stack合并结果\n",
    "- 在axis=0维度上堆叠，创建输出通道维度\n",
    "\n",
    "特点说明：\n",
    "1. **多维度处理**：\n",
    "   - 支持多输入通道\n",
    "   - 支持多输出通道\n",
    "   - 保持空间维度的卷积特性\n",
    "\n",
    "2. **模块化设计**：\n",
    "   - 复用corr2d_multi_in函数\n",
    "   - 清晰的层次结构\n",
    "   - 易于理解和维护\n",
    "\n",
    "3. **实际应用场景**：\n",
    "   - 深度神经网络中的卷积层\n",
    "   - 特征提取和转换\n",
    "   - 多特征图生成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    \"\"\"多输出通道二维卷积计算\"\"\"\n",
    "    #多通道的结果\n",
    "    results = []\n",
    "    # 遍历每个输出通道的卷积核\n",
    "    for k in K:\n",
    "        # 对当前卷积核执行多输入通道的互相关运算\n",
    "        result = corr2d_multi_in(X, k)\n",
    "        # 将结果添加到列表中\n",
    "        results.append(result)\n",
    "    # 将所有结果在新的轴上堆叠，形成多输出通道的结果\n",
    "    return tf.stack(results, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将核数组`K`同`K+1`（`K`中每个元素加一）和`K+2`连结在一起来构造一个输出通道数为3的卷积核。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 2, 2, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = tf.stack([K, K+1, K+2],axis=0)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们对输入数组`X`与核数组`K`做互相关运算。此时的输出含有3个通道。其中第一个通道的结果与之前输入数组`X`与多输入通道、单输出通道核的计算结果一致。\n",
    "\n",
    "## debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = corr2d_multi_in_out(X, K)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3.3 1x1 convolution\n",
    "\n",
    "最后我们讨论卷积窗口形状为$1\\times 1$（$k_h=k_w=1$）的多通道卷积层。我们通常称之为$1\\times 1$卷积层，并将其中的卷积运算称为$1\\times 1$卷积。因为使用了最小窗口，$1\\times 1$卷积失去了卷积层可以识别高和宽维度上相邻元素构成的模式的功能。实际上，$1\\times 1$卷积的主要计算发生在通道维上。图5.5展示了使用输入通道数为3、输出通道数为2的$1\\times 1$卷积核的互相关计算。值得注意的是，输入和输出具有相同的高和宽。输出中的每个元素来自输入中在高和宽上相同位置的元素在不同通道之间的按权重累加。假设我们将通道维当作特征维，将高和宽维度上的元素当成数据样本，那么$1\\times 1$卷积层的作用与全连接层等价。\n",
    "\n",
    "![使用输入通道数为3、输出通道数为2的$1\\times 1$卷积核的互相关计算。输入和输出具有相同的高和宽](../img/conv-1x1.svg)\n",
    "\n",
    "下面我们使用全连接层中的矩阵乘法来实现$1\\times 1$卷积。这里需要在矩阵乘法运算前后对数据形状做一些调整。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **函数定义和参数获取**：\n",
    "```python\n",
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "- X：输入数据，形状为(输入通道数, 高, 宽)\n",
    "- K：卷积核，形状为(输出通道数, 输入通道数, 1, 1)\n",
    "- 提取关键维度信息\n",
    "\n",
    "2. **数据重塑**：\n",
    "```python\n",
    "X = tf.reshape(X, (c_i, h * w))\n",
    "K = tf.reshape(K, (c_o, c_i))\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "重塑操作：\n",
    "- 输入X：从(c_i, h, w)变为(c_i, h*w)\n",
    "- 卷积核K：从(c_o, c_i, 1, 1)变为(c_o, c_i)\n",
    "\n",
    "3. **矩阵乘法和结果重塑**：\n",
    "```python\n",
    "Y = tf.matmul(K, X)\n",
    "return tf.reshape(Y, (c_o, h, w))\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "- 执行矩阵乘法：(c_o, c_i) × (c_i, h*w) = (c_o, h*w)\n",
    "- 将结果重塑回原始空间维度：(c_o, h, w)\n",
    "\n",
    "4. **调试信息**：\n",
    "```python\n",
    "print(f\"Y.shape: {Y.shape}, K.shape: {K.shape}, X.shape: {X.shape}\")\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "- 打印各个张量的形状\n",
    "- 帮助理解维度变化\n",
    "\n",
    "这个实现的特点：\n",
    "\n",
    "1. **计算效率**：\n",
    "   - 将1×1卷积转换为矩阵乘法\n",
    "   - 避免了显式的卷积运算\n",
    "   - 利用优化的矩阵运算库\n",
    "\n",
    "2. **1×1卷积的作用**：\n",
    "   - 调整通道数\n",
    "   - 跨通道信息整合\n",
    "   - 增加非线性（如果后接激活函数）\n",
    "\n",
    "3. **应用场景**：\n",
    "   - 网络中的瓶颈层\n",
    "   - 通道数降维/升维\n",
    "   - 跨通道特征融合\n",
    "\n",
    "这种实现方式展示了：\n",
    "- 1×1卷积的本质\n",
    "- 维度变换的技巧\n",
    "- 计算优化的思路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    \"\"\"\n",
    "    多输入通道、多输出通道的1x1卷积\n",
    "    \"\"\"\n",
    "    # 输入通道数、高、宽\n",
    "    c_i, h, w = X.shape\n",
    "    # 输出通道数\n",
    "    c_o = K.shape[0]\n",
    "    # 将输入X重塑为(输入通道数, 高*宽)的形状，将二维的单通道数据展平为一维\n",
    "    X = tf.reshape(X,(c_i, h * w))\n",
    "    # 将卷积核K重塑为(输出通道数, 输入通道数)的形状\n",
    "    K = tf.reshape(K,(c_o, c_i))\n",
    "    # 执行矩阵乘法，相当于1x1卷积操作\n",
    "    Y = tf.matmul(K, X)\n",
    "    print(f\"Y.shape: {Y.shape}, K.shape: {K.shape}, X.shape: {X.shape}\")\n",
    "    # 将结果重塑回原始的空间维度，得到(输出通道数, 高, 宽)的形状\n",
    "    return tf.reshape(Y, (c_o, h, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/conv-1x1-draft.png)\n",
    "图片内容是上述案例的思考过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y.shape: (2, 9), K.shape: (2, 3), X.shape: (3, 9)\n",
      "(2, 3, 3)\n",
      "(2, 3, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.random.uniform((3,3,3))\n",
    "K = tf.random.uniform((2,3,1,1))\n",
    "\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "print(Y1.shape)\n",
    "print(Y2.shape)\n",
    "\n",
    "\n",
    "tf.norm(Y1-Y2) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在之后的模型里我们将会看到$1\\times 1$卷积层被当作保持高和宽维度形状不变的全连接层使用。于是，我们可以通过调整网络层之间的通道数来控制模型复杂度。\n",
    "\n",
    "\n",
    "## 小结\n",
    "\n",
    "* 使用多通道可以拓展卷积层的模型参数。\n",
    "* 假设将通道维当作特征维，将高和宽维度上的元素当成数据样本，那么$1\\times 1$卷积层的作用与全连接层等价。\n",
    "* $1\\times 1$卷积层通常用来调整网络层之间的通道数，并控制模型复杂度。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
